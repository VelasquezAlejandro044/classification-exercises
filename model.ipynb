{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree\n",
    "\n",
    "---------------------\n",
    "# Exercises\n",
    "Using the titanic data, in your classification-exercises repository, create a notebook, model.ipynb where you will do the following:\n",
    "\n",
    "1. What is your baseline prediction? What is your baseline accuracy? remember: your baseline prediction for a classification problem is predicting the most prevelant class in the training dataset (the mode). When you make those predictions, what is your accuracy? This is your baseline accuracy.\n",
    "\n",
    "2. Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)\n",
    "\n",
    "3. Evaluate your in-sample results using the model score, confusion matrix, and classification report.\n",
    "\n",
    "4. Compute: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.\n",
    "\n",
    "5. Run through steps 2-4 using a different max_depth value.\n",
    "\n",
    "6. Which model performs better on your in-sample data?\n",
    "\n",
    "7. Which model performs best on your out-of-sample data, the validate set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import graphviz\n",
    "from graphviz import Graph\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import acquire\n",
    "import prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "2             2         1       3  female  26.0      0      0   7.9250   \n",
       "3             3         1       1  female  35.0      1      0  53.1000   \n",
       "4             4         0       3    male  35.0      0      0   8.0500   \n",
       "\n",
       "  embarked  class deck  embark_town  alone  \n",
       "0        S  Third  NaN  Southampton      0  \n",
       "1        C  First    C    Cherbourg      0  \n",
       "2        S  Third  NaN  Southampton      1  \n",
       "3        S  First    C  Southampton      0  \n",
       "4        S  Third  NaN  Southampton      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Acquire Step\n",
    "df = acquire.get_titanic_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the order of thte data frame based on passenger id \n",
    "df = df.set_index(\"passenger_id\")\n",
    "#Drop unesesary data\n",
    "df = df.drop(columns=[\"class\", \"embarked\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 0 to 890\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   survived     891 non-null    int64  \n",
      " 1   pclass       891 non-null    int64  \n",
      " 2   sex          891 non-null    object \n",
      " 3   age          714 non-null    float64\n",
      " 4   sibsp        891 non-null    int64  \n",
      " 5   parch        891 non-null    int64  \n",
      " 6   fare         891 non-null    float64\n",
      " 7   deck         203 non-null    object \n",
      " 8   embark_town  889 non-null    object \n",
      " 9   alone        891 non-null    int64  \n",
      "dtypes: float64(2), int64(5), object(3)\n",
      "memory usage: 76.6+ KB\n"
     ]
    }
   ],
   "source": [
    "#check for nulls and data types\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived         0\n",
       "pclass           0\n",
       "sex              0\n",
       "age            177\n",
       "sibsp            0\n",
       "parch            0\n",
       "fare             0\n",
       "deck           688\n",
       "embark_town      2\n",
       "alone            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We do not need Deck \n",
    "df = df.drop(columns=['deck'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's fill embark_town with the most common observation\n",
    "df.embark_town = df.embark_town.fillna(value=df.embark_town.mode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived         0\n",
       "pclass           0\n",
       "sex              0\n",
       "age            177\n",
       "sibsp            0\n",
       "parch            0\n",
       "fare             0\n",
       "embark_town      2\n",
       "alone            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check data status on nun values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It looks like there's nothing wildly different about the no age group compared to the population\n",
    "# So we'll impute using the median age\n",
    "df.age = df.age.fillna(value=df.age.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>passenger_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>889 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "passenger_id                                                          \n",
       "0                    0       3    male  22.0      1      0   7.2500   \n",
       "1                    1       1  female  38.0      1      0  71.2833   \n",
       "2                    1       3  female  26.0      0      0   7.9250   \n",
       "3                    1       1  female  35.0      1      0  53.1000   \n",
       "4                    0       3    male  35.0      0      0   8.0500   \n",
       "...                ...     ...     ...   ...    ...    ...      ...   \n",
       "886                  0       2    male  27.0      0      0  13.0000   \n",
       "887                  1       1  female  19.0      0      0  30.0000   \n",
       "888                  0       3  female  28.0      1      2  23.4500   \n",
       "889                  1       1    male  26.0      0      0  30.0000   \n",
       "890                  0       3    male  32.0      0      0   7.7500   \n",
       "\n",
       "              embark_town  alone  \n",
       "passenger_id                      \n",
       "0             Southampton      0  \n",
       "1               Cherbourg      0  \n",
       "2             Southampton      1  \n",
       "3             Southampton      0  \n",
       "4             Southampton      1  \n",
       "...                   ...    ...  \n",
       "886           Southampton      1  \n",
       "887           Southampton      1  \n",
       "888           Southampton      0  \n",
       "889             Cherbourg      1  \n",
       "890            Queenstown      1  \n",
       "\n",
       "[889 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop the rest of nulls \n",
    "df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived       0\n",
       "pclass         0\n",
       "sex            0\n",
       "age            0\n",
       "sibsp          0\n",
       "parch          0\n",
       "fare           0\n",
       "embark_town    2\n",
       "alone          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the distribution of values, it appears that no age subgroup is very close to the population\n",
    "# If we needed to be more certain, we could perform hypothesis testing\n",
    "# It looks like there's nothing wildly different about the no age group compared to the population\n",
    "# So we'll impute using the median age\n",
    "df.age = df.age.fillna(value=df.age.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>passenger_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              survived  pclass   age  sibsp  parch     fare  alone  sex_male  \\\n",
       "passenger_id                                                                   \n",
       "0                    0       3  22.0      1      0   7.2500      0         1   \n",
       "1                    1       1  38.0      1      0  71.2833      0         0   \n",
       "2                    1       3  26.0      0      0   7.9250      1         0   \n",
       "3                    1       1  35.0      1      0  53.1000      0         0   \n",
       "4                    0       3  35.0      0      0   8.0500      1         1   \n",
       "\n",
       "              embark_town_Queenstown  embark_town_Southampton  \n",
       "passenger_id                                                   \n",
       "0                                  0                        1  \n",
       "1                                  0                        0  \n",
       "2                                  0                        1  \n",
       "3                                  0                        1  \n",
       "4                                  0                        1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time to encode the encodeable!\n",
    "dummy_df = pd.get_dummies(df[['sex','embark_town']], dummy_na=False, drop_first=[True, True])\n",
    "\n",
    "# Drop the original columns we encoded\n",
    "df = df.drop(columns=[\"sex\", \"embark_town\"])\n",
    "\n",
    "# Stitch the df and the dummy_df together again\n",
    "df = pd.concat([df, dummy_df], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "train, test = train_test_split(df, test_size=.2, random_state=123, stratify=df.survived)\n",
    "train, validate = train_test_split(train, test_size=.3, random_state=123, stratify=train.survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=[\"survived\"])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=[\"survived\"])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=[\"survived\"])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. \n",
    "What is your baseline prediction? What is your baseline accuracy? remember: your baseline prediction for a classification problem is predicting the most prevelant class in the training dataset (the mode). When you make those predictions, what is your accuracy? This is your baseline accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    307\n",
       "1    191\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# base line prediction should be 0 \n",
    "train.survived.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 0.62\n"
     ]
    }
   ],
   "source": [
    "# The mode is a great baseline\n",
    "baseline = y_train.mode()\n",
    "\n",
    "# Produce a boolean array with True representing a match between the baseline prediction and reality\n",
    "matches_baseline_prediction = (y_train == 0)\n",
    "\n",
    "baseline_accuracy = matches_baseline_prediction.mean()\n",
    "print(f\"Baseline accuracy: {round(baseline_accuracy, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.\n",
    "Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the model\n",
    "tree1 = DecisionTreeClassifier(max_depth=1, random_state=123)\n",
    "\n",
    "# Fit the model (on train and only train)\n",
    "tree1 = tree1.fit(X_train, y_train)\n",
    "\n",
    "# Use the model\n",
    "# We'll evaluate the model's performance on train, first\n",
    "y_predictions = tree1.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.\n",
    "Evaluate your in-sample results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on training set: 0.80\n"
     ]
    }
   ],
   "source": [
    " print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "      .format(tree1.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>265</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  265   42\n",
       "1   58  133"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix - actual on left, predicted on top\n",
    "pd.DataFrame(confusion_matrix(y_train, y_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>265</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  265   42\n",
       "1   58  133"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix - actual on left, predicted on top\n",
    "pd.DataFrame(confusion_matrix(y_train, y_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree of 1 depth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.820433</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.799197</td>\n",
       "      <td>0.790217</td>\n",
       "      <td>0.797255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.863192</td>\n",
       "      <td>0.696335</td>\n",
       "      <td>0.799197</td>\n",
       "      <td>0.779764</td>\n",
       "      <td>0.799197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.841270</td>\n",
       "      <td>0.726776</td>\n",
       "      <td>0.799197</td>\n",
       "      <td>0.784023</td>\n",
       "      <td>0.797358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>307.000000</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>0.799197</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1  accuracy   macro avg  weighted avg\n",
       "precision    0.820433    0.760000  0.799197    0.790217      0.797255\n",
       "recall       0.863192    0.696335  0.799197    0.779764      0.799197\n",
       "f1-score     0.841270    0.726776  0.799197    0.784023      0.797358\n",
       "support    307.000000  191.000000  0.799197  498.000000    498.000000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Produce the classification report on the actual y values and this model's predicted y values\n",
    "report = classification_report(y_train, y_predictions, output_dict=True)\n",
    "print(\"Tree of 1 depth\")\n",
    "pd.DataFrame(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.\n",
    "Compute: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7991967871485943\n",
      "True Positive Rate: 0.8631921824104235\n",
      "False Positive Rate: 0.3036649214659686\n",
      "True Negative Rate: 0.6963350785340314\n",
      "False Negative Rate: 0.13680781758957655\n",
      "Precision: 0.8204334365325078\n",
      "Recall: 0.8631921824104235\n",
      "F1 Score: 0.8412698412698413\n",
      "Support (0): 307\n",
      "Support (1): 191\n"
     ]
    }
   ],
   "source": [
    "# based on confusion matrix and the fact that not-survived is our positive case \n",
    "TP = 265\n",
    "FP = 58\n",
    "FN = 42\n",
    "TN = 133\n",
    "ALL = TP + FP + FN + TN\n",
    "\n",
    "accuracy = (TP + TN)/ALL\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "true_positive_rate = TP/(TP+FN)\n",
    "print(f\"True Positive Rate: {true_positive_rate}\")\n",
    "\n",
    "false_positive_rate = FP/(FP+TN)\n",
    "print(f\"False Positive Rate: {false_positive_rate}\")\n",
    "\n",
    "true_negative_rate = TN/(TN+FP)\n",
    "print(f\"True Negative Rate: {true_negative_rate}\")\n",
    "\n",
    "false_negative_rate = FN/(FN+TP)\n",
    "print(f\"False Negative Rate: {false_negative_rate}\")\n",
    "\n",
    "precision = TP/(TP+FP)\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "recall = TP/(TP+FN)\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "f1_score = 2*(precision*recall)/(precision+recall)\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "\n",
    "support_pos = TP + FN\n",
    "print(f\"Support (0): {support_pos}\")\n",
    "\n",
    "support_neg = FP + TN\n",
    "print(f\"Support (1): {support_neg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.\n",
    "Run through steps 2-4 using a different max_depth value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree with max depth of 2\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.820433    0.760000  0.799197    0.790217      0.797255\n",
      "recall       0.863192    0.696335  0.799197    0.779764      0.799197\n",
      "f1-score     0.841270    0.726776  0.799197    0.784023      0.797358\n",
      "support    307.000000  191.000000  0.799197  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 3\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.829341    0.817073  0.825301    0.823207      0.824636\n",
      "recall       0.902280    0.701571  0.825301    0.801925      0.825301\n",
      "f1-score     0.864275    0.754930  0.825301    0.809602      0.822337\n",
      "support    307.000000  191.000000  0.825301  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 4\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.831858    0.842767  0.835341    0.837313      0.836042\n",
      "recall       0.918567    0.701571  0.835341    0.810069      0.835341\n",
      "f1-score     0.873065    0.765714  0.835341    0.819390      0.831892\n",
      "support    307.000000  191.000000  0.835341  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 5\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.852410    0.855422  0.853414    0.853916      0.853565\n",
      "recall       0.921824    0.743455  0.853414    0.832640      0.853414\n",
      "f1-score     0.885759    0.795518  0.853414    0.840639      0.851149\n",
      "support    307.000000  191.000000  0.853414  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 6\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.838983    0.930556  0.865462    0.884769      0.874104\n",
      "recall       0.967427    0.701571  0.865462    0.834499      0.865462\n",
      "f1-score     0.898638    0.800000  0.865462    0.849319      0.860807\n",
      "support    307.000000  191.000000  0.865462  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 7\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.887850    0.875706  0.883534    0.881778      0.883193\n",
      "recall       0.928339    0.811518  0.883534    0.869929      0.883534\n",
      "f1-score     0.907643    0.842391  0.883534    0.875017      0.882617\n",
      "support    307.000000  191.000000  0.883534  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 8\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.874636    0.954839  0.899598    0.914737      0.905396\n",
      "recall       0.977199    0.774869  0.899598    0.876034      0.899598\n",
      "f1-score     0.923077    0.855491  0.899598    0.889284      0.897156\n",
      "support    307.000000  191.000000  0.899598  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 9\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.905488    0.941176  0.917671    0.923332      0.919176\n",
      "recall       0.967427    0.837696  0.917671    0.902562      0.917671\n",
      "f1-score     0.935433    0.886427  0.917671    0.910930      0.916637\n",
      "support    307.000000  191.000000  0.917671  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 10\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.931250    0.949438  0.937751    0.940344      0.938226\n",
      "recall       0.970684    0.884817  0.937751    0.927750      0.937751\n",
      "f1-score     0.950558    0.915989  0.937751    0.933274      0.937300\n",
      "support    307.000000  191.000000  0.937751  498.000000    498.000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's \n",
    "for i in range(2, 11):\n",
    "    # Make the model\n",
    "    tree = DecisionTreeClassifier(max_depth=i, random_state=123)\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    tree = tree.fit(X_train, y_train)\n",
    "\n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    y_predictions = tree.predict(X_train)\n",
    "\n",
    "    # Produce the classification report on the actual y values and this model's predicted y values\n",
    "    report = classification_report(y_train, y_predictions, output_dict=True)\n",
    "    print(f\"Tree with max depth of {i}\")\n",
    "    print(pd.DataFrame(report))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.\n",
    "Which model performs better on your in-sample data?\n",
    "\n",
    "#10 has the highest accuaracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.\n",
    "Which model performs best on your out-of-sample data, the validate set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.799197</td>\n",
       "      <td>0.761682</td>\n",
       "      <td>0.037515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.825301</td>\n",
       "      <td>0.799065</td>\n",
       "      <td>0.026236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.835341</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.040949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.853414</td>\n",
       "      <td>0.799065</td>\n",
       "      <td>0.054348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0.865462</td>\n",
       "      <td>0.789720</td>\n",
       "      <td>0.075742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>0.883534</td>\n",
       "      <td>0.780374</td>\n",
       "      <td>0.103160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>0.899598</td>\n",
       "      <td>0.789720</td>\n",
       "      <td>0.109879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>0.917671</td>\n",
       "      <td>0.799065</td>\n",
       "      <td>0.118605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>0.937751</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.152704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>0.955823</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>0.142739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12</td>\n",
       "      <td>0.971888</td>\n",
       "      <td>0.822430</td>\n",
       "      <td>0.149458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>0.981928</td>\n",
       "      <td>0.827103</td>\n",
       "      <td>0.154825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14</td>\n",
       "      <td>0.989960</td>\n",
       "      <td>0.817757</td>\n",
       "      <td>0.172203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>0.180892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>0.180892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>17</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>0.180892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>0.180892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>19</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>0.180892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>0.180892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>21</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>0.180892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>22</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>0.180892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>23</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>0.180892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>24</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>0.180892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>25</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>0.180892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>26</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>0.180892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>27</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>0.180892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>28</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>0.180892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>29</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>0.180892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>30</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>0.180892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>31</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>0.180892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>32</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>0.180892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>33</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>0.180892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>34</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>0.180892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  train_accuracy  validate_accuracy  difference\n",
       "0           2        0.799197           0.761682    0.037515\n",
       "1           3        0.825301           0.799065    0.026236\n",
       "2           4        0.835341           0.794393    0.040949\n",
       "3           5        0.853414           0.799065    0.054348\n",
       "4           6        0.865462           0.789720    0.075742\n",
       "5           7        0.883534           0.780374    0.103160\n",
       "6           8        0.899598           0.789720    0.109879\n",
       "7           9        0.917671           0.799065    0.118605\n",
       "8          10        0.937751           0.785047    0.152704\n",
       "9          11        0.955823           0.813084    0.142739\n",
       "10         12        0.971888           0.822430    0.149458\n",
       "11         13        0.981928           0.827103    0.154825\n",
       "12         14        0.989960           0.817757    0.172203\n",
       "13         15        0.993976           0.813084    0.180892\n",
       "14         16        0.993976           0.813084    0.180892\n",
       "15         17        0.993976           0.813084    0.180892\n",
       "16         18        0.993976           0.813084    0.180892\n",
       "17         19        0.993976           0.813084    0.180892\n",
       "18         20        0.993976           0.813084    0.180892\n",
       "19         21        0.993976           0.813084    0.180892\n",
       "20         22        0.993976           0.813084    0.180892\n",
       "21         23        0.993976           0.813084    0.180892\n",
       "22         24        0.993976           0.813084    0.180892\n",
       "23         25        0.993976           0.813084    0.180892\n",
       "24         26        0.993976           0.813084    0.180892\n",
       "25         27        0.993976           0.813084    0.180892\n",
       "26         28        0.993976           0.813084    0.180892\n",
       "27         29        0.993976           0.813084    0.180892\n",
       "28         30        0.993976           0.813084    0.180892\n",
       "29         31        0.993976           0.813084    0.180892\n",
       "30         32        0.993976           0.813084    0.180892\n",
       "31         33        0.993976           0.813084    0.180892\n",
       "32         34        0.993976           0.813084    0.180892"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's continue getting loopy, so we can compare in-sample to out-of-sample\n",
    "metrics = []\n",
    "\n",
    "for i in range(2, 35):\n",
    "    # Make the model\n",
    "    tree = DecisionTreeClassifier(max_depth=i, random_state=123)\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    tree = tree.fit(X_train, y_train)\n",
    "\n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    in_sample_accuracy = tree.score(X_train, y_train)\n",
    "    \n",
    "    out_of_sample_accuracy = tree.score(X_validate, y_validate)\n",
    "\n",
    "    output = {\n",
    "        \"max_depth\": i,\n",
    "        \"train_accuracy\": in_sample_accuracy,\n",
    "        \"validate_accuracy\": out_of_sample_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "    \n",
    "df = pd.DataFrame(metrics)\n",
    "df[\"difference\"] = df.train_accuracy - df.validate_accuracy\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.825301</td>\n",
       "      <td>0.799065</td>\n",
       "      <td>0.026236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.853414</td>\n",
       "      <td>0.799065</td>\n",
       "      <td>0.054348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.835341</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.040949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0.865462</td>\n",
       "      <td>0.789720</td>\n",
       "      <td>0.075742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.799197</td>\n",
       "      <td>0.761682</td>\n",
       "      <td>0.037515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_depth  train_accuracy  validate_accuracy  difference\n",
       "1          3        0.825301           0.799065    0.026236\n",
       "3          5        0.853414           0.799065    0.054348\n",
       "2          4        0.835341           0.794393    0.040949\n",
       "4          6        0.865462           0.789720    0.075742\n",
       "0          2        0.799197           0.761682    0.037515"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.difference <= 0.10].sort_values(by=['validate_accuracy', 'difference'], ascending = [False,True])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "-----------------------\n",
    "# Exercises\n",
    "1. Continue working in your model file with titanic data to do the following:\n",
    "\n",
    "2. Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 10.\n",
    "\n",
    "3. Evaluate your results using the model score, confusion matrix, and classification report.\n",
    "\n",
    "4. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.\n",
    "\n",
    "5. Run through steps increasing your min_samples_leaf and decreasing your max_depth.\n",
    "\n",
    "6. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?\n",
    "\n",
    "7. After making a few models, which one has the best performance (or closest metrics) on both train and validate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.\n",
    "Continue working in your model file with titanic data to do the following:\n",
    "\n",
    "# 2.\n",
    "Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from pydataset import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "2             2         1       3  female  26.0      0      0   7.9250   \n",
       "3             3         1       1  female  35.0      1      0  53.1000   \n",
       "4             4         0       3    male  35.0      0      0   8.0500   \n",
       "\n",
       "  embarked  class deck  embark_town  alone  \n",
       "0        S  Third  NaN  Southampton      0  \n",
       "1        C  First    C    Cherbourg      0  \n",
       "2        S  Third  NaN  Southampton      1  \n",
       "3        S  First    C  Southampton      0  \n",
       "4        S  Third  NaN  Southampton      1  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Acquire Step\n",
    "df = acquire.get_titanic_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((498, 9), (214, 9), (179, 9))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_validate.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 0.62\n"
     ]
    }
   ],
   "source": [
    "# The mode is a great baseline\n",
    "baseline = y_train.mode()\n",
    "\n",
    "# Produce a boolean array with True representing a match between the baseline prediction and reality\n",
    "matches_baseline_prediction = y_train == 0\n",
    "\n",
    "baseline_accuracy = matches_baseline_prediction.mean()\n",
    "print(f\"Baseline accuracy: {round(baseline_accuracy, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree of 1 depth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.773481</td>\n",
       "      <td>0.801471</td>\n",
       "      <td>0.781124</td>\n",
       "      <td>0.787476</td>\n",
       "      <td>0.784216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.912052</td>\n",
       "      <td>0.570681</td>\n",
       "      <td>0.781124</td>\n",
       "      <td>0.741366</td>\n",
       "      <td>0.781124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.837070</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.781124</td>\n",
       "      <td>0.751868</td>\n",
       "      <td>0.771715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>307.000000</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>0.781124</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1  accuracy   macro avg  weighted avg\n",
       "precision    0.773481    0.801471  0.781124    0.787476      0.784216\n",
       "recall       0.912052    0.570681  0.781124    0.741366      0.781124\n",
       "f1-score     0.837070    0.666667  0.781124    0.751868      0.771715\n",
       "support    307.000000  191.000000  0.781124  498.000000    498.000000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make the model\n",
    "forest1 = RandomForestClassifier(max_depth=1, random_state=123)\n",
    "\n",
    "# Fit the model \n",
    "forest1.fit(X_train, y_train)\n",
    "\n",
    "# Use the model\n",
    "# Evaluate model's performance on train\n",
    "y_predictions = forest1.predict(X_train)\n",
    "\n",
    "# Produce the classification report on the actual y values and this model's predicted y values\n",
    "report = classification_report(y_train, y_predictions, output_dict=True)\n",
    "print(\"Tree of 1 depth\")\n",
    "pd.DataFrame(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, random_state=5)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(min_samples_leaf=1, max_depth=10, random_state=5)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08826559, 0.21605137, 0.04852438, 0.03212837, 0.24533209,\n",
       "       0.01873577, 0.31065655, 0.01549838, 0.02480751])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf_train = rf.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.\n",
    "Evaluate your results using the model score, confusion matrix, and classification report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9698795180722891"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[307,   0],\n",
       "       [ 15, 176]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, y_pred_rf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98       307\n",
      "           1       1.00      0.92      0.96       191\n",
      "\n",
      "    accuracy                           0.97       498\n",
      "   macro avg       0.98      0.96      0.97       498\n",
      "weighted avg       0.97      0.97      0.97       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred_rf_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.\n",
    "Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[307,   0],\n",
       "       [ 15, 176]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, y_pred_rf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'accuracy: 0.9698795180722891, tpr: 1.0, fpr: -2064.0666666666666, tnr: 2065.0666666666666, fnr: 0.0, precision: 1.0, recall: 0.9214659685863874, f1: 0.9591280653950953'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp = 307\n",
    "fp = 15\n",
    "tn = 176\n",
    "fn = 1\n",
    "accuracy = accuracy_score(y_train, y_pred_rf_train)\n",
    "tpr = tp / (tp / fn)\n",
    "tnr = tn / (fp / tn) \n",
    "fpr = 1 - tnr # fp / (fp + tn)\n",
    "fnr = 1 - tpr # fn / (fn + tp)\n",
    "precision = precision_score(y_train, y_pred_rf_train)\n",
    "recall = recall_score(y_train, y_pred_rf_train)\n",
    "f1 = f1_score(y_train, y_pred_rf_train)\n",
    "f\"accuracy: {accuracy}, tpr: {tpr}, fpr: {fpr}, tnr: {tnr}, fnr: {fnr}, precision: {precision}, recall: {recall}, f1: {f1}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98       307\n",
      "           1       1.00      0.92      0.96       191\n",
      "\n",
      "    accuracy                           0.97       498\n",
      "   macro avg       0.98      0.96      0.97       498\n",
      "weighted avg       0.97      0.97      0.97       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred_rf_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.\n",
    "Run through steps increasing your min_samples_leaf and decreasing your max_depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=6, min_samples_leaf=4, random_state=5)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf1 = RandomForestClassifier(min_samples_leaf=4, max_depth=6, random_state=5)\n",
    "rf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12056514, 0.10557004, 0.04688489, 0.02223547, 0.16989799,\n",
       "       0.01813543, 0.48230977, 0.01323384, 0.02116744])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf1.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8654618473895582"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_rf1_train = rf1.predict(X_train)\n",
    "rf1.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[294,  13],\n",
       "       [ 54, 137]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, y_pred_rf1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.90       307\n",
      "           1       0.91      0.72      0.80       191\n",
      "\n",
      "    accuracy                           0.87       498\n",
      "   macro avg       0.88      0.84      0.85       498\n",
      "weighted avg       0.87      0.87      0.86       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred_rf1_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.\n",
    "What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_samples_per_leaf</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.821285</td>\n",
       "      <td>0.771028</td>\n",
       "      <td>0.050257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.845382</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.060335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.847390</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.052997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.859438</td>\n",
       "      <td>0.799065</td>\n",
       "      <td>0.060372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.861446</td>\n",
       "      <td>0.799065</td>\n",
       "      <td>0.062380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.863454</td>\n",
       "      <td>0.789720</td>\n",
       "      <td>0.073734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.863454</td>\n",
       "      <td>0.789720</td>\n",
       "      <td>0.073734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0.855422</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.061029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.857430</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.072383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>0.849398</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.064351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0.839357</td>\n",
       "      <td>0.780374</td>\n",
       "      <td>0.058984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0.839357</td>\n",
       "      <td>0.780374</td>\n",
       "      <td>0.058984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0.835341</td>\n",
       "      <td>0.780374</td>\n",
       "      <td>0.054968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>0.835341</td>\n",
       "      <td>0.789720</td>\n",
       "      <td>0.045622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0.835341</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.050295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0.825301</td>\n",
       "      <td>0.780374</td>\n",
       "      <td>0.044927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>0.823293</td>\n",
       "      <td>0.789720</td>\n",
       "      <td>0.033574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>0.835341</td>\n",
       "      <td>0.775701</td>\n",
       "      <td>0.059640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    min_samples_per_leaf  max_depth  train_accuracy  validate_accuracy  \\\n",
       "0                      2          2        0.821285           0.771028   \n",
       "1                      3          3        0.845382           0.785047   \n",
       "2                      4          4        0.847390           0.794393   \n",
       "3                      5          5        0.859438           0.799065   \n",
       "4                      6          6        0.861446           0.799065   \n",
       "5                      7          7        0.863454           0.789720   \n",
       "6                      8          8        0.863454           0.789720   \n",
       "7                      9          9        0.855422           0.794393   \n",
       "8                     10         10        0.857430           0.785047   \n",
       "9                     11         11        0.849398           0.785047   \n",
       "10                    12         12        0.839357           0.780374   \n",
       "11                    13         13        0.839357           0.780374   \n",
       "12                    14         14        0.835341           0.780374   \n",
       "13                    15         15        0.835341           0.789720   \n",
       "14                    16         16        0.835341           0.785047   \n",
       "15                    17         17        0.825301           0.780374   \n",
       "16                    18         18        0.823293           0.789720   \n",
       "17                    19         19        0.835341           0.775701   \n",
       "\n",
       "    difference  \n",
       "0     0.050257  \n",
       "1     0.060335  \n",
       "2     0.052997  \n",
       "3     0.060372  \n",
       "4     0.062380  \n",
       "5     0.073734  \n",
       "6     0.073734  \n",
       "7     0.061029  \n",
       "8     0.072383  \n",
       "9     0.064351  \n",
       "10    0.058984  \n",
       "11    0.058984  \n",
       "12    0.054968  \n",
       "13    0.045622  \n",
       "14    0.050295  \n",
       "15    0.044927  \n",
       "16    0.033574  \n",
       "17    0.059640  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's continue getting loopy, so we can compare in-sample to out-of-sample\n",
    "metrics = []\n",
    "max_depth = 20\n",
    "\n",
    "for i in range(2, max_depth):\n",
    "    # Make the model\n",
    "    depth = i\n",
    "    n_samples = i\n",
    "    forest = RandomForestClassifier(max_depth=depth, min_samples_leaf=n_samples, random_state=123)\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    forest = forest.fit(X_train, y_train)\n",
    "\n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    in_sample_accuracy = forest.score(X_train, y_train)\n",
    "    \n",
    "    out_of_sample_accuracy = forest.score(X_validate, y_validate)\n",
    "\n",
    "    output = {\n",
    "        \"min_samples_per_leaf\": n_samples,\n",
    "        \"max_depth\": depth,\n",
    "        \"train_accuracy\": in_sample_accuracy,\n",
    "        \"validate_accuracy\": out_of_sample_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "    \n",
    "df = pd.DataFrame(metrics)\n",
    "df[\"difference\"] = df.train_accuracy - df.validate_accuracy\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[['train_accuracy', 'validate_accuracy','difference']].plot()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_samples_per_leaf</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.861446</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.067053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.859438</td>\n",
       "      <td>0.789720</td>\n",
       "      <td>0.069718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.857430</td>\n",
       "      <td>0.789720</td>\n",
       "      <td>0.067710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.859438</td>\n",
       "      <td>0.799065</td>\n",
       "      <td>0.060372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.859438</td>\n",
       "      <td>0.789720</td>\n",
       "      <td>0.069718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.851406</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.066359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.855422</td>\n",
       "      <td>0.789720</td>\n",
       "      <td>0.065702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.845382</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.060335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.847390</td>\n",
       "      <td>0.780374</td>\n",
       "      <td>0.067016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>0.839357</td>\n",
       "      <td>0.780374</td>\n",
       "      <td>0.058984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>0.841365</td>\n",
       "      <td>0.775701</td>\n",
       "      <td>0.065665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>0.841365</td>\n",
       "      <td>0.780374</td>\n",
       "      <td>0.060992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>0.827309</td>\n",
       "      <td>0.789720</td>\n",
       "      <td>0.037590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>0.831325</td>\n",
       "      <td>0.789720</td>\n",
       "      <td>0.041606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>0.827309</td>\n",
       "      <td>0.789720</td>\n",
       "      <td>0.037590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>0.825301</td>\n",
       "      <td>0.780374</td>\n",
       "      <td>0.044927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>0.821285</td>\n",
       "      <td>0.789720</td>\n",
       "      <td>0.031566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>0.829317</td>\n",
       "      <td>0.775701</td>\n",
       "      <td>0.053616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.829317</td>\n",
       "      <td>0.775701</td>\n",
       "      <td>0.053616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>0.829317</td>\n",
       "      <td>0.789720</td>\n",
       "      <td>0.039598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>0.831325</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.046279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>0.761682</td>\n",
       "      <td>0.057595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>0.771028</td>\n",
       "      <td>0.048249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>0.807229</td>\n",
       "      <td>0.766355</td>\n",
       "      <td>0.040874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>0.807229</td>\n",
       "      <td>0.761682</td>\n",
       "      <td>0.045547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>0.805221</td>\n",
       "      <td>0.761682</td>\n",
       "      <td>0.043539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>0.807229</td>\n",
       "      <td>0.766355</td>\n",
       "      <td>0.040874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>0.807229</td>\n",
       "      <td>0.761682</td>\n",
       "      <td>0.045547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>0.813253</td>\n",
       "      <td>0.757009</td>\n",
       "      <td>0.056244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>0.811245</td>\n",
       "      <td>0.757009</td>\n",
       "      <td>0.054236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>0.805221</td>\n",
       "      <td>0.766355</td>\n",
       "      <td>0.038866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>33</td>\n",
       "      <td>5</td>\n",
       "      <td>0.799197</td>\n",
       "      <td>0.761682</td>\n",
       "      <td>0.037515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>0.807229</td>\n",
       "      <td>0.757009</td>\n",
       "      <td>0.050220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>0.807229</td>\n",
       "      <td>0.757009</td>\n",
       "      <td>0.050220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>36</td>\n",
       "      <td>5</td>\n",
       "      <td>0.807229</td>\n",
       "      <td>0.757009</td>\n",
       "      <td>0.050220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>0.807229</td>\n",
       "      <td>0.766355</td>\n",
       "      <td>0.040874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>0.809237</td>\n",
       "      <td>0.766355</td>\n",
       "      <td>0.042882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.809237</td>\n",
       "      <td>0.766355</td>\n",
       "      <td>0.042882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>0.807229</td>\n",
       "      <td>0.766355</td>\n",
       "      <td>0.040874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>41</td>\n",
       "      <td>5</td>\n",
       "      <td>0.807229</td>\n",
       "      <td>0.766355</td>\n",
       "      <td>0.040874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "      <td>0.801205</td>\n",
       "      <td>0.766355</td>\n",
       "      <td>0.034850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>43</td>\n",
       "      <td>5</td>\n",
       "      <td>0.805221</td>\n",
       "      <td>0.761682</td>\n",
       "      <td>0.043539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>44</td>\n",
       "      <td>5</td>\n",
       "      <td>0.799197</td>\n",
       "      <td>0.757009</td>\n",
       "      <td>0.042187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>0.801205</td>\n",
       "      <td>0.766355</td>\n",
       "      <td>0.034850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>0.783133</td>\n",
       "      <td>0.757009</td>\n",
       "      <td>0.026123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>47</td>\n",
       "      <td>5</td>\n",
       "      <td>0.783133</td>\n",
       "      <td>0.757009</td>\n",
       "      <td>0.026123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>0.781124</td>\n",
       "      <td>0.757009</td>\n",
       "      <td>0.024115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>49</td>\n",
       "      <td>5</td>\n",
       "      <td>0.781124</td>\n",
       "      <td>0.757009</td>\n",
       "      <td>0.024115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    min_samples_per_leaf  max_depth  train_accuracy  validate_accuracy  \\\n",
       "0                      2          5        0.861446           0.794393   \n",
       "1                      3          5        0.859438           0.789720   \n",
       "2                      4          5        0.857430           0.789720   \n",
       "3                      5          5        0.859438           0.799065   \n",
       "4                      6          5        0.859438           0.789720   \n",
       "5                      7          5        0.851406           0.785047   \n",
       "6                      8          5        0.855422           0.789720   \n",
       "7                      9          5        0.845382           0.785047   \n",
       "8                     10          5        0.847390           0.780374   \n",
       "9                     11          5        0.839357           0.780374   \n",
       "10                    12          5        0.841365           0.775701   \n",
       "11                    13          5        0.841365           0.780374   \n",
       "12                    14          5        0.827309           0.789720   \n",
       "13                    15          5        0.831325           0.789720   \n",
       "14                    16          5        0.827309           0.789720   \n",
       "15                    17          5        0.825301           0.780374   \n",
       "16                    18          5        0.821285           0.789720   \n",
       "17                    19          5        0.829317           0.775701   \n",
       "18                    20          5        0.829317           0.775701   \n",
       "19                    21          5        0.829317           0.789720   \n",
       "20                    22          5        0.831325           0.785047   \n",
       "21                    23          5        0.819277           0.761682   \n",
       "22                    24          5        0.819277           0.771028   \n",
       "23                    25          5        0.807229           0.766355   \n",
       "24                    26          5        0.807229           0.761682   \n",
       "25                    27          5        0.805221           0.761682   \n",
       "26                    28          5        0.807229           0.766355   \n",
       "27                    29          5        0.807229           0.761682   \n",
       "28                    30          5        0.813253           0.757009   \n",
       "29                    31          5        0.811245           0.757009   \n",
       "30                    32          5        0.805221           0.766355   \n",
       "31                    33          5        0.799197           0.761682   \n",
       "32                    34          5        0.807229           0.757009   \n",
       "33                    35          5        0.807229           0.757009   \n",
       "34                    36          5        0.807229           0.757009   \n",
       "35                    37          5        0.807229           0.766355   \n",
       "36                    38          5        0.809237           0.766355   \n",
       "37                    39          5        0.809237           0.766355   \n",
       "38                    40          5        0.807229           0.766355   \n",
       "39                    41          5        0.807229           0.766355   \n",
       "40                    42          5        0.801205           0.766355   \n",
       "41                    43          5        0.805221           0.761682   \n",
       "42                    44          5        0.799197           0.757009   \n",
       "43                    45          5        0.801205           0.766355   \n",
       "44                    46          5        0.783133           0.757009   \n",
       "45                    47          5        0.783133           0.757009   \n",
       "46                    48          5        0.781124           0.757009   \n",
       "47                    49          5        0.781124           0.757009   \n",
       "\n",
       "    difference  \n",
       "0     0.067053  \n",
       "1     0.069718  \n",
       "2     0.067710  \n",
       "3     0.060372  \n",
       "4     0.069718  \n",
       "5     0.066359  \n",
       "6     0.065702  \n",
       "7     0.060335  \n",
       "8     0.067016  \n",
       "9     0.058984  \n",
       "10    0.065665  \n",
       "11    0.060992  \n",
       "12    0.037590  \n",
       "13    0.041606  \n",
       "14    0.037590  \n",
       "15    0.044927  \n",
       "16    0.031566  \n",
       "17    0.053616  \n",
       "18    0.053616  \n",
       "19    0.039598  \n",
       "20    0.046279  \n",
       "21    0.057595  \n",
       "22    0.048249  \n",
       "23    0.040874  \n",
       "24    0.045547  \n",
       "25    0.043539  \n",
       "26    0.040874  \n",
       "27    0.045547  \n",
       "28    0.056244  \n",
       "29    0.054236  \n",
       "30    0.038866  \n",
       "31    0.037515  \n",
       "32    0.050220  \n",
       "33    0.050220  \n",
       "34    0.050220  \n",
       "35    0.040874  \n",
       "36    0.042882  \n",
       "37    0.042882  \n",
       "38    0.040874  \n",
       "39    0.040874  \n",
       "40    0.034850  \n",
       "41    0.043539  \n",
       "42    0.042187  \n",
       "43    0.034850  \n",
       "44    0.026123  \n",
       "45    0.026123  \n",
       "46    0.024115  \n",
       "47    0.024115  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What about a fixed depth and increasing min_samples_leaf\n",
    "\n",
    "# Let's continue getting loopy, so we can compare in-sample to out-of-sample\n",
    "metrics = []\n",
    "\n",
    "\n",
    "for i in range(2, 50):\n",
    "    # Make the model\n",
    "    depth = 5\n",
    "    n_samples = i\n",
    "    forest = RandomForestClassifier(max_depth=depth, min_samples_leaf=n_samples, random_state=123)\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    forest = forest.fit(X_train, y_train)\n",
    "\n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    in_sample_accuracy = forest.score(X_train, y_train)\n",
    "    \n",
    "    out_of_sample_accuracy = forest.score(X_validate, y_validate)\n",
    "\n",
    "    output = {\n",
    "        \"min_samples_per_leaf\": n_samples,\n",
    "        \"max_depth\": depth,\n",
    "        \"train_accuracy\": in_sample_accuracy,\n",
    "        \"validate_accuracy\": out_of_sample_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "    \n",
    "df = pd.DataFrame(metrics)\n",
    "df[\"difference\"] = df.train_accuracy - df.validate_accuracy\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.set_index('min_samples_per_leaf')[['train_accuracy', 'validate_accuracy', 'difference']].plot(figsize = (16,9))\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(np.arange(0,50,5))\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN\n",
    "--------\n",
    "# Exercises\n",
    "Continue working in your model file with the titanic dataset.\n",
    "\n",
    "1. Fit a K-Nearest Neighbors classifier to your training sample and transform (i.e. make predictions on the training sample)\n",
    "\n",
    "2. Evaluate your results using the model score, confusion matrix, and classification report.\n",
    "\n",
    "3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.\n",
    "\n",
    "4. Run through steps 2-4 setting k to 10\n",
    "\n",
    "5. Run through setps 2-4 setting k to 20\n",
    "\n",
    "6. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?\n",
    "\n",
    "7. Which model performs best on our out-of-sample data from validate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. \n",
    "Fit a K-Nearest Neighbors classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = acquire.get_titanic_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((498, 10), (214, 10), (179, 10))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5, weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_classification_metrics(knn)\n",
    "y_pred = knn.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.\n",
    "Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83       307\n",
      "           1       0.73      0.73      0.73       191\n",
      "\n",
      "    accuracy                           0.79       498\n",
      "   macro avg       0.78      0.78      0.78       498\n",
      "weighted avg       0.79      0.79      0.79       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbour = 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.731579</td>\n",
       "      <td>0.793173</td>\n",
       "      <td>0.781374</td>\n",
       "      <td>0.792973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.833876</td>\n",
       "      <td>0.727749</td>\n",
       "      <td>0.793173</td>\n",
       "      <td>0.780812</td>\n",
       "      <td>0.793173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.832520</td>\n",
       "      <td>0.729659</td>\n",
       "      <td>0.793173</td>\n",
       "      <td>0.781090</td>\n",
       "      <td>0.793069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>307.000000</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>0.793173</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1  accuracy   macro avg  weighted avg\n",
       "precision    0.831169    0.731579  0.793173    0.781374      0.792973\n",
       "recall       0.833876    0.727749  0.793173    0.780812      0.793173\n",
       "f1-score     0.832520    0.729659  0.793173    0.781090      0.793069\n",
       "support    307.000000  191.000000  0.793173  498.000000    498.000000"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = classification_report(y_train, y_pred, output_dict=True)\n",
    "print(\"n_neighbour = 5\")\n",
    "pd.DataFrame(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[256,  51],\n",
       "       [ 52, 139]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual on Left, Predicted on Top\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>survived</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>256</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0       0    1\n",
       "survived          \n",
       "0         256   51\n",
       "1          52  139"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Actual on Left, Predicted on Top')\n",
    "pd.crosstab(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.\n",
    "Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 51, 52, 139)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Positive outcome is survival = 1\n",
    "TN, FP, FN, TP = confusion_matrix(y_train,y_pred).ravel()\n",
    "ALL = TP + TN + FP + FN\n",
    "\n",
    "TN, FP, FN, TP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-61-066944a63058>, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-61-066944a63058>\"\u001b[0;36m, line \u001b[0;32m11\u001b[0m\n\u001b[0;31m    support:{train[\"survived\"].value_counts()}\"\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "tpr = tp / (tp / fn)\n",
    "tnr = tn / (fp / tn) \n",
    "fpr = 1 - tnr # fp / (fp + tn)\n",
    "fnr = 1 - tpr # fn / (fn + tp)\n",
    "precision = precision_score(y_train, y_pred)\n",
    "recall = recall_score(y_train, y_pred)\n",
    "f1 = f1_score(y_train, y_pred)\n",
    "f\"accuracy: {accuracy}, tpr: {tpr}, fpr: {fpr}, tnr: {tnr}, \\\n",
    "fnr: {fnr}, precision: {precision}, recall: {recall}, f1: {f1}, \\\n",
    "support:{train[\"survived\"].value_counts()}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fuction to show ,pde; score given the confusion matrix \n",
    "def show_scores(TN, FP, FN, TP):\n",
    "    \n",
    "    ALL = TP + TN + FP + FN\n",
    "    \n",
    "    accuracy = (TP + TN)/ALL # How often did the model get it right?\n",
    "    precision = TP/(TP+FP) # What is the quality of a positive prediction made by the model?\n",
    "    recall = TP/(TP+FN) # How many of the true positives were found?   \n",
    "    \n",
    "    true_positive_rate = TP/(TP+FN) # Same as recall, actually\n",
    "    true_negative_rate = TN/(TN+FP) # How many of the true negatives were found?\n",
    "    false_positive_rate = FP/(FP+TN) # How often did we miss the negative and accidentally call it positive?\n",
    "    false_negative_rate = FN/(FN+TP) # How often did we miss the positive and accidentally call it negative?\n",
    "    \n",
    "    f1_score = 2*(precision*recall)/(precision+recall) # Harmonic mean, good for imbalanced data sets\n",
    "    support_pos = TP + FN # Number of actual positives in the sample\n",
    "    support_neg = FP + TN # Number of actual negatives in the sample\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"True Positive Rate: {true_positive_rate}\")\n",
    "    print(f\"True Negative Rate: {true_negative_rate}\")\n",
    "    print(f\"False Positive Rate: {false_positive_rate}\")\n",
    "    print(f\"False Negative Rate: {false_negative_rate}\")\n",
    "    print(f\"F1 Score: {f1_score}\")\n",
    "    print(f\"Support (0): {support_pos}\")\n",
    "    print(f\"Support (1): {support_neg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7931726907630522\n",
      "Precision: 0.7315789473684211\n",
      "Recall: 0.7277486910994765\n",
      "True Positive Rate: 0.7277486910994765\n",
      "True Negative Rate: 0.8338762214983714\n",
      "False Positive Rate: 0.16612377850162866\n",
      "False Negative Rate: 0.27225130890052357\n",
      "F1 Score: 0.7296587926509187\n",
      "Support (0): 191\n",
      "Support (1): 307\n"
     ]
    }
   ],
   "source": [
    "show_scores(TN, FP, FN, TP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. \n",
    "Run through steps 2-4 setting k to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbour = 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.743935</td>\n",
       "      <td>0.755906</td>\n",
       "      <td>0.746988</td>\n",
       "      <td>0.749920</td>\n",
       "      <td>0.748526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.899023</td>\n",
       "      <td>0.502618</td>\n",
       "      <td>0.746988</td>\n",
       "      <td>0.700820</td>\n",
       "      <td>0.746988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.814159</td>\n",
       "      <td>0.603774</td>\n",
       "      <td>0.746988</td>\n",
       "      <td>0.708966</td>\n",
       "      <td>0.733469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>307.000000</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>0.746988</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1  accuracy   macro avg  weighted avg\n",
       "precision    0.743935    0.755906  0.746988    0.749920      0.748526\n",
       "recall       0.899023    0.502618  0.746988    0.700820      0.746988\n",
       "f1-score     0.814159    0.603774  0.746988    0.708966      0.733469\n",
       "support    307.000000  191.000000  0.746988  498.000000    498.000000"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn2 = KNeighborsClassifier(n_neighbors=10, weights='uniform')\n",
    "knn2.fit(X_train, y_train)\n",
    "# get_classification_metrics(knn)\n",
    "y_pred2 = knn2.predict(X_train)\n",
    "\n",
    "report = classification_report(y_train, y_pred2, output_dict=True)\n",
    "print(\"n_neighbour = 10\")\n",
    "pd.DataFrame(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual on Left, Predicted on Top\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>survived</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>276</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0       0   1\n",
       "survived         \n",
       "0         276  31\n",
       "1          95  96"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion_matrix\n",
    "print('Actual on Left, Predicted on Top')\n",
    "pd.crosstab(y_train, y_pred2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. \n",
    "Run through setps 2-4 setting k to 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbour = 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.723118</td>\n",
       "      <td>0.698413</td>\n",
       "      <td>0.716867</td>\n",
       "      <td>0.710765</td>\n",
       "      <td>0.713643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.876221</td>\n",
       "      <td>0.460733</td>\n",
       "      <td>0.716867</td>\n",
       "      <td>0.668477</td>\n",
       "      <td>0.716867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.792342</td>\n",
       "      <td>0.555205</td>\n",
       "      <td>0.716867</td>\n",
       "      <td>0.673773</td>\n",
       "      <td>0.701392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>307.000000</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>0.716867</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1  accuracy   macro avg  weighted avg\n",
       "precision    0.723118    0.698413  0.716867    0.710765      0.713643\n",
       "recall       0.876221    0.460733  0.716867    0.668477      0.716867\n",
       "f1-score     0.792342    0.555205  0.716867    0.673773      0.701392\n",
       "support    307.000000  191.000000  0.716867  498.000000    498.000000"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn3 = KNeighborsClassifier(n_neighbors=20, weights='uniform')\n",
    "knn3.fit(X_train, y_train)\n",
    "# get_classification_metrics(knn)\n",
    "y_pred3 = knn3.predict(X_train)\n",
    "\n",
    "report = classification_report(y_train, y_pred3, output_dict=True)\n",
    "print(\"n_neighbour = 10\")\n",
    "pd.DataFrame(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual on Left, Predicted on Top\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>survived</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>269</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>103</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0       0   1\n",
       "survived         \n",
       "0         269  38\n",
       "1         103  88"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion_matrix\n",
    "print('Actual on Left, Predicted on Top')\n",
    "pd.crosstab(y_train, y_pred3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.\n",
    "What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?\n",
    "- It seems that the less amount of neighbors the better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.\n",
    "Which model performs best on our out-of-sample data from validate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics = []\n",
    "\n",
    "# loop through different values of k\n",
    "for k in range(1, 21):\n",
    "            \n",
    "    # define the thing\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    \n",
    "    # fit the thing (remmeber only fit on training data)\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    # use the thing (calculate accuracy)\n",
    "    train_accuracy = knn.score(X_train, y_train)\n",
    "    validate_accuracy = knn.score(X_validate, y_validate)\n",
    "    \n",
    "    output = {\n",
    "        \"k\": k,\n",
    "        \"train_accuracy\": train_accuracy,\n",
    "        \"validate_accuracy\": validate_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "\n",
    "# make a dataframe\n",
    "results = pd.DataFrame(metrics)\n",
    "\n",
    "# plot the data\n",
    "results.set_index('k').plot(figsize = (16,9))\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(np.arange(0,21,1))\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "--------\n",
    "# Exercises\n",
    "\n",
    "In these exercises, we'll continue working with the titanic dataset and building logistic regression models. Throughout this exercise, be sure you are training, evaluation, and comparing models on the train and validate datasets. The test dataset should only be used for your final model.\n",
    "\n",
    "For all of the models you create, choose a threshold that optimizes for accuracy.\n",
    "\n",
    "Do your work for these exercises in either a notebook or a python script named model within your classification-exercises repository. Add, commit, and push your work.\n",
    "\n",
    "1. Create a model that includes age in addition to fare and pclass. Does this model perform better than your baseline?\n",
    "\n",
    "2. Include sex in your model as well. Note that you'll need to encode or create a dummy variable of this feature before including it in a model.\n",
    "\n",
    "3. Try out other combinations of features and models.\n",
    "\n",
    "4. Use you best 3 models to predict and evaluate on your validate sample.\n",
    "\n",
    "5. Choose you best model from the validation performation, and evaluate it on the test dataset. How do the performance metrics compare to validate? to train?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.\n",
    "Create a model that includes age in addition to fare and pclass. Does this model perform better than your baseline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>passenger_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.125</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>20.525</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              survived  pclass   age  sibsp  parch    fare  alone  sex_male  \\\n",
       "passenger_id                                                                  \n",
       "583                  0       1  36.0      0      0  40.125      1         1   \n",
       "165                  1       3   9.0      0      2  20.525      0         1   \n",
       "\n",
       "              embark_town_Queenstown  embark_town_Southampton  \n",
       "passenger_id                                                   \n",
       "583                                0                        0  \n",
       "165                                0                        1  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_accuracy = (train.survived == 0).mean()\n",
    "round(baseline_accuracy, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline is 0.62\n",
      "Logistic Regression using age, pclass, and fare features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.70\n"
     ]
    }
   ],
   "source": [
    "# Create the logistic regression\n",
    "logit = LogisticRegression(random_state=123)\n",
    "\n",
    "# specify the features we're using\n",
    "features = [\"age\", \"pclass\", \"fare\"]\n",
    "\n",
    "# Fit a model using only these specified features\n",
    "# logit.fit(X_train[[\"age\", \"pclass\", \"fare\"]], y_train)\n",
    "logit.fit(X_train[features], y_train)\n",
    "\n",
    "# Since we .fit on a subset, we .predict on that same subset of features\n",
    "y_pred = logit.predict(X_train[features])\n",
    "\n",
    "print(\"Baseline is\", round(baseline_accuracy, 2))\n",
    "print(\"Logistic Regression using age, pclass, and fare features\")\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X_train[features], y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.\n",
    "Include sex in your model as well. Note that you'll need to encode or create a dummy variable of this feature before including it in a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression using age, pclass, fare, and gender features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.81\n"
     ]
    }
   ],
   "source": [
    "# Create the logistic regression\n",
    "logit1 = LogisticRegression(random_state=123)\n",
    "\n",
    "# specify the features we're using\n",
    "features = [\"age\", \"pclass\", \"fare\", \"sex_male\"]\n",
    "\n",
    "# Fit a model using only these specified features\n",
    "logit1.fit(X_train[features], y_train)\n",
    "\n",
    "y_pred = logit1.predict(X_train[features])\n",
    "\n",
    "print(\"Logistic Regression using age, pclass, fare, and gender features\")\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit1.score(X_train[features], y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. \n",
    "Try out other combinations of features and models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.85       307\n",
      "           1       0.78      0.72      0.75       191\n",
      "\n",
      "    accuracy                           0.82       498\n",
      "   macro avg       0.81      0.80      0.80       498\n",
      "weighted avg       0.81      0.82      0.81       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logr1 = LogisticRegression(penalty=\"l2\", max_iter=500, solver=\"lbfgs\", random_state=5, C=0.5)\n",
    "logr1.fit(X_train, y_train)\n",
    "logr1.score(X_train, y_train)\n",
    "y_pred_l_train = logr1.predict(X_train)\n",
    "print(classification_report(y_train, y_pred_l_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.95      0.79       307\n",
      "           1       0.78      0.26      0.39       191\n",
      "\n",
      "    accuracy                           0.69       498\n",
      "   macro avg       0.73      0.61      0.59       498\n",
      "weighted avg       0.72      0.69      0.64       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logr2 = LogisticRegression(penalty=\"l2\", max_iter=500, solver=\"sag\", random_state=5, C=0.25)\n",
    "logr2.fit(X_train, y_train)\n",
    "logr2.score(X_train, y_train)\n",
    "y_pred_2_train = logr2.predict(X_train)\n",
    "print(classification_report(y_train, y_pred_2_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.88      0.85       307\n",
      "           1       0.78      0.70      0.73       191\n",
      "\n",
      "    accuracy                           0.81       498\n",
      "   macro avg       0.80      0.79      0.79       498\n",
      "weighted avg       0.81      0.81      0.80       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logr3 = LogisticRegression(penalty=\"l1\", max_iter=500, solver=\"liblinear\", random_state=5, C=0.25)\n",
    "logr3.fit(X_train, y_train)\n",
    "logr3.score(X_train, y_train)\n",
    "y_pred_3_train = logr3.predict(X_train)\n",
    "print(classification_report(y_train, y_pred_3_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.85       307\n",
      "           1       0.78      0.72      0.75       191\n",
      "\n",
      "    accuracy                           0.82       498\n",
      "   macro avg       0.81      0.80      0.80       498\n",
      "weighted avg       0.81      0.82      0.81       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logr4 = LogisticRegression(random_state=123, C=0.0001)\n",
    "logr4.fit(X_train, y_train)\n",
    "\n",
    "y_pred_4_train = logr4.predict(X_train)\n",
    "accuracy = logr4.score(X_train, y_train)\n",
    "\n",
    "y_pred_4_train = logr1.predict(X_train)\n",
    "print(classification_report(y_train, y_pred_4_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.\n",
    "Use you best 3 models to predict and evaluate on your validate sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.83       132\n",
      "           1       0.75      0.65      0.69        82\n",
      "\n",
      "    accuracy                           0.78       214\n",
      "   macro avg       0.77      0.75      0.76       214\n",
      "weighted avg       0.78      0.78      0.78       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_l = logr1.predict(X_validate)\n",
    "print(classification_report(y_validate, y_pred_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81       132\n",
      "           1       0.71      0.66      0.68        82\n",
      "\n",
      "    accuracy                           0.77       214\n",
      "   macro avg       0.75      0.75      0.75       214\n",
      "weighted avg       0.76      0.77      0.76       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_3 = logr3.predict(X_validate)\n",
    "print(classification_report(y_validate, y_pred_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.98      0.79       132\n",
      "           1       0.83      0.18      0.30        82\n",
      "\n",
      "    accuracy                           0.67       214\n",
      "   macro avg       0.75      0.58      0.54       214\n",
      "weighted avg       0.73      0.67      0.60       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_4 = logr4.predict(X_validate)\n",
    "print(classification_report(y_validate, y_pred_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 5.\n",
    "Choose you best model from the validation performation, and evaluate it on the test dataset. How do the performance metrics compare to validate? to train?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.84       110\n",
      "           1       0.77      0.71      0.74        69\n",
      "\n",
      "    accuracy                           0.80       179\n",
      "   macro avg       0.80      0.79      0.79       179\n",
      "weighted avg       0.80      0.80      0.80       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_1 = logr1.predict(X_test)\n",
    "print(classification_report(y_test, y_test_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
